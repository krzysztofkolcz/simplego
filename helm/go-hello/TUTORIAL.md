# Kurs: WdroÅ¼enie prostego programu Go z Helm â€” krok po kroku
To chyba nie jest dokladnie ta konwersacja, ale podobne:
https://chatgpt.com/c/69038bcb-f20c-8326-b77d-5d3f159093da

Ten kurs prowadzi CiÄ™ od *najprostszego* programu w Go do dziaÅ‚ajÄ…cego wdroÅ¼enia na klastrze Kubernetes przy uÅ¼yciu Helm. ZakÅ‚adam, Å¼e masz lokalny klaster (minikube / kind / k3d / klaster w chmurze) oraz `kubectl`, `helm`, `docker`/`podman` i `git`.

> Czas wykonania: ~60â€“120 minut w zaleÅ¼noÅ›ci od Å›rodowiska.

---

## Spis treÅ›ci

1. Wymagania wstÄ™pne
2. Utworzenie prostego programu w Go (HTTP server)
3. Dockerfile i budowanie obrazu
4. WypchniÄ™cie obrazu do rejestru (Docker Hub / GitHub Container Registry)
5. Utworzenie podstawowego Helm Charta
6. Dostosowanie tpl: Deployment, Service, ConfigMap
7. WartoÅ›ci `values.yaml` i nadpisywanie
8. Instalacja Chartu i sprawdzenie
9. Aktualizacje (upgrade) i rollback
10. Dodanie Ingress / TLS (opcjonalnie)
11. NajczÄ™stsze problemy i debugowanie
12. Rozszerzenia (CI/CD, liveness/readiness, secrets)

---

## 1. Wymagania wstÄ™pne

* `go` (>= 1.18)
* `docker` lub `podman` (lub `kaniko`/`buildx` do budowy obrazÃ³w)
* `kubectl` skonfigurowane do Twojego klastra
* `helm` (3.x)
* konto w Docker Hub lub GHCR (jeÅ›li pushujesz obraz zdalnie)

SprawdÅº:

```bash
go version
docker --version
kubectl version --client
helm version
```

---

## 2. Prosty program w Go â€” `main.go`

StwÃ³rz katalog projektu `go-hello` i plik `main.go`:

```go
package main

import (
    "fmt"
    "net/http"
    "os"
)

func handler(w http.ResponseWriter, r *http.Request) {
    name := os.Getenv("APP_NAME")
    if name == "" {
        name = "go-hello"
    }
    fmt.Fprintf(w, "Hello from %s!\n", name)
}

func main() {
    http.HandleFunc("/", handler)
    port := ":8080"
    http.ListenAndServe(port, nil)
}
```

Szybki build i test lokalny:

```bash
go mod init example.com/go-hello
go mod tidy
go run main.go
# potem: curl http://localhost:8080
```

---

## 3. Dockerfile

Prosty, niewielki obraz:

```dockerfile
# syntax=docker/dockerfile:1
FROM golang:1.20-alpine AS build
WORKDIR /src
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -o /app ./

FROM alpine:3.18
COPY --from=build /app /app
EXPOSE 8080
ENV APP_NAME=go-hello
ENTRYPOINT ["/app"]
```

Zbuduj lokalnie:

```bash
docker build -t kkolcz/go-hello:0.1.0 .
```

```makefile
make build-image
```

Uwaga na rÃ³zne wersje go w Dockerfile i go.mod!

## Uruchomienie rejestru, klastra k3d, import image do rejestru
```
k3d cluster create go-hello-cluster \
  --registry-create go-hello-registry:0.0.0.0:5000
```

```makefile
# 0
create-k3d-cluster-with-registry
	k3d cluster create $(CLUSTER_NAME) -p "30083:30083@server:0" --api-port 127.0.0.1:6445 --registry-create $(REGISTRY_NAME):$(REGISTRY_PORT); \
  ...
```

lub osobno (ale z tym mialem problemy testujac):
```
k3d registry create go-hello-registry --port 5000
k3d cluster create go-hello-cluster --registry-use k3d-go-hello-registry:5000
```

Tagowanie image
```
docker build -t kkolcz/go-hello:0.1.0 .
docker tag kkolcz/go-hello:0.1.0 k3d-go-hello-registry:5000/kkolcz/go-hello:0.1.0
```
```makefile
# 1
build-image:
	docker build -t $(TAG) .

# 2
tag-image:
	docker tag $(TAG) localhost:$(REGISTRY_PORT)/$(TAG)
	docker tag $(TAG) $(REGISTRY_NAME):$(REGISTRY_PORT)/$(TAG)
```


k3d-$(REGISTRY_NAME):$(REGISTRY_PORT)/$(TAG) 
to jest â€tylkoâ€ tag, ale ten tag ma bardzo konkretne znaczenie â€“ wskazuje do jakiego rejestru Docker ma wysÅ‚aÄ‡ obraz.


Pushowanie image. Registry dostepne z hosta pod adresem localhost:5000
WyjaÅ›nienie dlaczego pushuje na localhost:5000 a nie na k3d-go-hello-registry:5000
https://chatgpt.com/c/69666347-4bc0-8327-96f3-2ce4ba80eca4

Chodzi o to, ze k3d-go-hello-registry:5000 jest dostepne wewnatrz sieci kubernetesa, a nie z hosta.
```
docker push localhost:5000/kkolcz/go-hello:0.1.0
```
```makefile
# 3
k3d-import-image: build-image
	@echo "Importing docker image into k3d"
	docker push localhost:$(REGISTRY_PORT)/$(TAG)
```
Musze otagowac image jako localhost:$(REGISTRY_PORT)/$(TAG)

### Import image bez rejestru

```bash
docker build -t kkolcz/go-hello:0.1.0 .
k3d image import --cluster go-hello-cluster kkolcz/go-hello:0.1.0
```

### Push obrazu do rejestru (np. Docker Hub)

Zaloguj siÄ™ i wypchnij:

```bash
docker login
docker push kkolcz/go-hello:0.1.0
```

## List komend
### Lista klastrow
```
k3d cluster list

```

### Rejestr

pobranie obrazow z lokalnego registry (dziala dla rejstru lokalnego na porcie 5000)
```
curl http://localhost:5000/v2/_catalog
```

lista tagow:
```
curl http://localhost:5000/v2/kkolcz/go-hello/tags/list
```

## 5. Tworzymy Helm Chart

UÅ¼yj `helm create`:

```bash
helm create go-hello
```

To stworzy strukturÄ™:

```
go-hello/
  Chart.yaml
  values.yaml
  templates/
    deployment.yaml
    service.yaml
    ingress.yaml
    _helpers.tpl
```

### Warto usuwaÄ‡ zbÄ™dne rzeczy.

https://chatgpt.com/c/69791d1b-3608-832b-b24f-97d6499c5a8c

Usuniemy zbÄ™dne rzeczy i zostawimy minimalny chart.
Chart ma opisywaÄ‡ to, co faktycznie deployujesz â€“ nie wszystko, co Helm potrafi.
Czyli:
âŒ nie zostawiamy â€bo moÅ¼e siÄ™ przydaâ€
âœ… zostawiamy tylko to, co realnie uÅ¼ywane
ğŸ“‰ im mniejszy chart â†’ mniej bÅ‚Ä™dÃ³w â†’ Å‚atwiejsze utrzymanie

### Co robi helm create w praktyce?
helm create generuje demo-chart:
pod wszystkie moÅ¼liwe use-caseâ€™y
edukacyjny
nie produkcyjny
Dlatego masz tam m.in.:
ingress.yaml
hpa.yaml
serviceaccount.yaml
tests/
masÄ™ opcji w values.yaml

WiÄ™kszoÅ›Ä‡ projektÃ³w uÅ¼ywa 20â€“30% tego, co tam jest.

Na razie usuwam
./go-hello/templates/hpa.yaml
./go-hello/templates/NOTES.txt

### Co zdecydowanie warto usuwaÄ‡, jeÅ›li nie uÅ¼ywasz
âŒ templates/
UsuÅ„ bez Å¼alu, jeÅ›li nie korzystasz:
templates/hpa.yaml
â†’ jeÅ›li nie masz HPA
templates/ingress.yaml
â†’ jeÅ›li ingress masz poza chartem albo innym toolâ€™em
templates/serviceaccount.yaml
â†’ jeÅ›li uÅ¼ywasz default SA
templates/tests/*
â†’ jeÅ›li nie robisz helm testÃ³w
templates/NOTES.txt
â†’ jeÅ›li nikt tego nie czyta (99% zespoÅ‚Ã³w)

âŒ values.yaml

To jest najwiÄ™kszy anty-pattern:

autoscaling:
  enabled: false


JeÅ›li nie planujesz autoscalingu â†’ usuÅ„ caÅ‚Ä… sekcjÄ™.
Dlaczego?
ktoÅ› kiedyÅ› ustawi enabled: true
HPA siÄ™ stworzy
prod zacznie Å¼yÄ‡ wÅ‚asnym Å¼yciem ğŸ˜¬

Co zostawiÄ‡ zawsze (core)

Minimum sensownego chartu:

Chart.yaml
values.yaml
templates/
  deployment.yaml
  service.yaml
  _helpers.tpl


To jest solidny fundament 90% aplikacji backendowych.

Kiedy warto coÅ› zostawiÄ‡ â€na przyszÅ‚oÅ›Ä‡â€?

Tylko jeÅ›li:

masz konkretny plan (np. HPA w Q2)

i komentarz dlaczego jest wyÅ‚Ä…czone

PrzykÅ‚ad OK:

# Planned: enable HPA after load tests (Q2 2026)
autoscaling:
  enabled: false


PrzykÅ‚ad âŒ:

autoscaling:
  enabled: false

---

## 6. Dostosowanie szablonÃ³w

### `values.yaml` â€” przykÅ‚ad

```yaml
replicaCount: 1

image:
  # repository: kkolcz/go-hello
  repository: go-hello-registry:5000/kkolcz/go-hello
  pullPolicy: IfNotPresent
  tag: "0.1.0"

service:
  type: ClusterIP
  port: 80

app:
  name: go-hello
  env:
    - name: APP_NAME
      value: "go-hello-from-helm"
```

### `templates/deployment.yaml` â€” minimalny deployment
To Å›wiadomo odchudzona wersja deployment.yaml.
Usuwam (z pomocÄ… chata) niepotrzebne czÄ™Å›ci:

#### Co dokÅ‚adnie wyciÄ…Å‚eÅ› (Å›wiadomie)?
Element	Dlaczego out
autoscaling	nie potrzebujesz na start
serviceAccount	default wystarcza
securityContext	Go app + non-root pÃ³Åºniej
liveness/readiness	dodaje siÄ™, gdy endpointy gotowe
resources	brak limitÃ³w = mniej throttlingu na dev
volumes	config przez ENV
affinity/tolerations	overkill
imagePullSecrets	local / public registry

Najlepsza strategia (i dokÅ‚adnie to, co zrobiÅ‚eÅ›):
Start: minimalny Deployment
A potem dokÅ‚adaÄ‡ elementy Å›wiadomie, gdy:
wiesz po co

PrzykÅ‚ad:
â€pody ginÄ…â€ â†’ livenessProbe
â€OOMKilledâ€ â†’ resources
â€multi-AZâ€ â†’ affinity
â€sekretyâ€ â†’ volumes + secrets

#### deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "go-hello.fullname" . }}
  labels:
    app.kubernetes.io/name: {{ include "go-hello.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "go-hello.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include "go-hello.name" . }}
        app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - containerPort: 8080
          env:
{{ toYaml .Values.app.env | indent 12 }}
```

### `templates/service.yaml` â€” prosty service

```yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ include "go-hello.fullname" . }}
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: 8080
  selector:
    app.kubernetes.io/name: {{ include "go-hello.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
```
## WyjaÅ›nienie go template engine wykorzystywanego w helm chart
### {{ include "..." }}
```
name: {{ include "go-hello.fullname" . }}
```

include = funkcja Helm, ktÃ³ra wywoÅ‚uje definicjÄ™ helpera z _helpers.tpl
"go-hello.fullname" = nazwa helpera (w _helpers.tpl np. funkcja tworzÄ…ca peÅ‚nÄ… nazwÄ™ release)
. = kontekst caÅ‚ego release (wszystkie wartoÅ›ci .Values, .Release, itd.)

### {{ .Values... }}
```
type: {{ .Values.service.type }}
```

.Values â†’ zawartoÅ›Ä‡ pliku values.yaml
.Values.service.type â†’ bierze wartoÅ›Ä‡ z:
```
service:
  type: ClusterIP
```
Wynik w YAML:
```
type: ClusterIP
```
### {{ .Release.Name }}
Selector: include "go-hello.name" . i .Release.Name
```
selector:
  app.kubernetes.io/name: {{ include "go-hello.name" . }}
  app.kubernetes.io/instance: {{ .Release.Name }}
```
include "go-hello.name" . â†’ helper w _helpers.tpl ktÃ³ry zwraca np. samÄ… nazwÄ™ chartu (go-hello)
.Release.Name â†’ nazwa release podana przy helm install demo ... â†’ np. demo

JeÅ›li instalujesz z:
```
helm install myapp ./go-hello
```
to .Release.Name = myapp.

### Funkcje Golangowe â€“ np. toYaml, indent, upper
```
{{ toYaml .Values.app.env | indent 12 }}
```

toYaml konwertuje strukturÄ™ z values.yaml do YAML.
| indent 12 dodaje 12 spacji wciÄ™cia, Å¼eby byÅ‚o poprawnie w YAML.

### {{ .Chart.Name }}
.Chart â€“ informacje o samym chartcie z Chart.yaml:
```
name: {{ .Chart.Name }}  # go-hello
version: {{ .Chart.Version }}  # 0.1.0
```

## 7. WartoÅ›ci i nadpisywanie

PrzykÅ‚ad instalacji:

```bash
helm install demo ./go-hello -f ./go-hello/values.yaml
```

```makefile
# 3
k3d-install-helm:
	helm install $(RELEASE) $(CHART_DIR) -f $(CHART_DIR)/values.yaml
```

Nadpisanie pojedynczej wartoÅ›ci:

```bash
helm install demo ./go-hello --set image.tag=0.1.1
```

PodglÄ…d renderowanych manifestÃ³w:

```bash
helm template demo ./go-hello -f ./go-hello/values.yaml
# lub
helm install --dry-run --debug demo ./go-hello -f ./go-hello/values.yaml
```

---

### Podglad
```
helm template demo ./go-hello -f ./go-hello/values.yaml
---
# Source: go-hello/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-custom-config
data:
  postgresql.conf: |
    log_lock_waits = on
    log_min_duration_statement = 0
    log_statement = 'all'
---
```
```
# Source: go-hello/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: demo-go-hello
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 8080
  selector:
    app.kubernetes.io/name: go-hello
    app.kubernetes.io/instance: demo
```
Co to robi:
Service w Kubernetes dziaÅ‚a jak wewnÄ™trzny load balancer / DNS dla podÃ³w.
type: ClusterIP â†’ serwis dostÄ™pny tylko w klastrze.
ports:
port: 80 â†’ port, pod ktÃ³rym service jest dostÄ™pny dla innych podÃ³w.
targetPort: 8080 â†’ port w kontenerze (deployment) do ktÃ³rego ruch jest przekierowywany.
selector:
Service Å‚Ä…czy siÄ™ z podami, ktÃ³re majÄ… te etykiety (app.kubernetes.io/name: go-hello, app.kubernetes.io/instance: demo).
ğŸ’¡ Efekt: inne pod-y w klastrze mogÄ… zrobiÄ‡ curl http://demo-go-hello i trafiÄ… na pod go-hello.

```
---
# Source: go-hello/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-go-hello
  labels:
    app.kubernetes.io/name: go-hello
    app.kubernetes.io/instance: demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: go-hello
      app.kubernetes.io/instance: demo
  template:
    metadata:
      labels:
        app.kubernetes.io/name: go-hello
        app.kubernetes.io/instance: demo
    spec:
      containers:
        - name: go-hello
          image: "kkolcz/go-hello:0.1.0"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
          env:
            - name: APP_NAME
              value: go-hello-from-helm
```
Deployment zarzÄ…dza replikami podÃ³w â€“ zapewnia, Å¼e w klastrze zawsze dziaÅ‚a okreÅ›lona liczba podÃ³w.
replicas: 1 â†’ chcemy 1 pod.
selector â†’ mÃ³wi Deploymentowi, ktÃ³re pody zarzÄ…dzaÄ‡ (etykiety).
template â†’ szablon poda, ktÃ³ry Deployment tworzy.
containers â†’ kontener go-hello:
image â†’ obraz Dockera (kkolcz/go-hello:0.1.0)
imagePullPolicy: IfNotPresent â†’ pobiera obraz tylko jeÅ›li go nie ma lokalnie
ports â†’ port 8080 w kontenerze
env â†’ zmienna Å›rodowiskowa APP_NAME ustawiona na go-hello-from-helm
Efekt:
Deployment tworzy pod z Twoim kontenerem
Service demo-go-hello Å‚Ä…czy siÄ™ z tym podem przez port 80 â†’ 8080

```
---
# Source: go-hello/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "demo-go-hello-test-connection"
  labels:
    helm.sh/chart: go-hello-0.1.0
    app.kubernetes.io/name: go-hello
    app.kubernetes.io/instance: demo
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['demo-go-hello:80']
  restartPolicy: Never
```
To jest Helm test hook ("helm.sh/hook": test) â†’ uruchamiany po wdroÅ¼eniu przez helm test.
Tworzy pod tymczasowy:
Kontener busybox z poleceniem wget demo-go-hello:80
Celem jest sprawdzenie, czy Service dziaÅ‚a i odpowiada.
restartPolicy: Never â†’ pod nie jest restartowany automatycznie
ğŸ’¡ Po teÅ›cie pod zostanie usuniÄ™ty przez Helm (nie zostaje w klastrze).

## 8. Instalacja i sprawdzenie

Zainstaluj:

```bash
helm upgrade --install demo ./go-hello -f ./go-hello/values.yaml
```

SprawdÅº zasoby:

```bash
kubectl get deployments
kubectl get pods
kubectl get svc
kubectl logs -l app.kubernetes.io/name=go-hello
```

JeÅ¼eli uÅ¼ywasz `minikube` lub `kind` (na k3d tez dziala), otwÃ³rz port:

```bash
kubectl port-forward svc/demo-go-hello 8080:80
# potem: curl http://localhost:8080
```

---

## 9. Aktualizacje i rollback

Aktualizacja obrazu i tagu w `values.yaml`, potem:

```bash
helm upgrade demo ./go-hello -f values.yaml
```

Rollback do poprzedniej wersji:

```bash
helm rollback demo 1
```

SprawdÅº historiÄ™:

```bash
helm history demo
```

---

## 10. Ingress i TLS (opcjonalnie)

JeÅ¼eli masz Ingress Controller (nginx/traefik), w `values.yaml` ustaw `ingress.enabled: true` i dodaj host. Do TLS uÅ¼yj cert-manager lub wbudowanej obsÅ‚ugi (Let's Encrypt).

---

## 11. Debugowanie â€” najczÄ™stsze problemy

* Pod w CrashLoop: `kubectl logs pod -c <container>` i `kubectl describe pod`.
* Obraz nie Å›ciÄ…ga siÄ™: sprawdÅº `imagePullSecrets` i `imagePullPolicy`.
* Helm renderuje zÅ‚e wartoÅ›ci: uÅ¼yj `helm template` i sprawdÅº `values.yaml` i `--set`.

---

## 12. Rozszerzenia i dobre praktyki

* Liveness & readiness probes w `deployment.yaml`.
* Resource requests/limits.
* ConfigMap & Secret zamiast env dla wraÅ¼liwych danych.
* CI: GitHub Actions / GitLab CI â€” budowa obrazu, push, `helm upgrade --install`.
* UÅ¼yj `helm test` do testÃ³w smoke po wdroÅ¼eniu.

---

## 13. PrzykÅ‚adowy minimalny workflow CI (schemat)

1. Push do `main`
2. CI: buduj obraz, taguj, push
3. CI: `helm upgrade --install` na klasterze staging
4. Smoke tests
5. (opcjonalnie) promuj do produkcji

---

## 14. Co moÅ¼esz zrobiÄ‡ dalej (zadania)

* Dodaj readiness/liveness.
* Dodaj autoscaling (HorizontalPodAutoscaler).
* Dodaj sekret z DB connection string i poÅ‚Ä…cz z aplikacjÄ….
* Zintegruj z GitHub Actions â€” automatyczne deploye.

---

### Gotowe repo przykÅ‚adowe

JeÅ›li chcesz, mogÄ™:

* wygenerowaÄ‡ strukturÄ™ repo z peÅ‚nym przykÅ‚adem (Go + Dockerfile + Helm) i przygotowaÄ‡ instrukcjÄ™ `README`,
* lub przygotowaÄ‡ plik `values` dla produkcji (resources, probes, PVC, ingress),
* lub napisaÄ‡ pipeline CI (GitHub Actions).

Powiedz, ktÃ³re z tych chcesz teraz â€” zrobiÄ™ to natychmiast.


## Widocznosc na zewnatrz
### port-forward
```
kubectl port-forward svc/demo-go-hello 8080:80
```

```
localhost:8080
    â†“
Service demo-go-hello :80
    â†“
Pod :8080
```
### NodePort
```
service:
  type: NodePort
  port: 80
  nodePort: 30080
```
wtedy:
```
kubectl get nodes -o wide
```

i otwierasz:
```
http://localhost:30080
```

### Ingress
JeÅ›li masz ingress-nginx w k3d
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: go-hello
spec:
  rules:
    - host: go-hello.localhost
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: demo-go-hello
                port:
                  number: 80
```
dodajesz do /etc/hosts:
```
127.0.0.1 go-hello.localhost
```
```
http://go-hello.localhost
```

## MAKEFILE
### k3d kubeconfig merge
```
k3d kubeconfig merge  $(CLUSTER_NAME) 
```

dodaje kubeconfig klastra k3d do Twojego lokalnego ~/.kube/config
i (opcjonalnie) przeÅ‚Ä…cza aktualny context.
KaÅ¼dy klaster k3d ma wÅ‚asny kubeconfig, ktÃ³ry k3d trzyma wewnÄ™trznie (nie zawsze zapisany w ~/.kube/config).
ta komenda robi:
pobiera kubeconfig tylko dla tego klastra
scala (merge) go z:
~/.kube/config

Co dokÅ‚adnie trafia do kubeconfig?
Dodawane sÄ…
```
clusters:
- name: k3d-go-hello-cluster
  cluster:
    server: https://127.0.0.1:6443
    certificate-authority-data: ...

users:
- name: admin@k3d-go-hello-cluster
  user:
    client-certificate-data: ...
    client-key-data: ...

contexts:
- name: k3d-go-hello-cluster
  context:
    cluster: k3d-go-hello-cluster
    user: admin@k3d-go-hello-cluster

```


### Co robi --kubeconfig-switch-context?
To automatycznie ustawia nowy klaster jako aktywny context.

Aktualny kontekst zwroci:
```
kubectl config current-context
```


# Postgresql dziaÅ‚ajÄ…cy tutorial
https://chatgpt.com/c/69749b70-6264-832a-add3-52d079e4dc6b

PoniÅ¼ej masz praktyczny tutorial krok-po-kroku, oparty o Helm + chart Bitnami, ktÃ³ry jest najczÄ™Å›ciej uÅ¼ywany w produkcji i devie.

ZakÅ‚adam, Å¼e:
masz dziaÅ‚ajÄ…cy klaster Kubernetes
masz zainstalowane: kubectl i helm
pracujesz lokalnie (np. minikube / k3s / DOKS / EKS)
Tutorial: PostgreSQL w Kubernetes + baza danych + uÅ¼ytkownik

## 1. SprawdÅº wersje
kubectl version --client
helm version

## 2. UtwÃ³rz namespace (zalecane)
kubectl create namespace database

## 3. Dodaj repozytorium Helm Bitnami
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update

## 4. Przygotuj plik values.yaml

UtwÃ³rz plik postgresql/values.yaml:
(architektonicznie, lepiej nie Å‚Ä…czyÄ‡ plikÃ³w values.yaml i postgresql-values.yaml)
values.yaml - values dla chartu aplikacji

POPRAWNE PODEJÅšCIE #1 (najlepsze): osobne charty + osobne values
Struktura repo

```
helm/
â”œâ”€â”€ go-hello/
â”‚   â”œâ”€â”€ Chart.yaml
â”‚   â”œâ”€â”€ values.yaml
â”‚   â””â”€â”€ templates/
â”‚
â””â”€â”€ postgresql/
    â””â”€â”€ values.yaml
```

postgresql/values.yaml:
```
auth:
  username: appuser
  password: strongpassword
  database: appdb
  postgresPassword: superadminpassword

primary:
  persistence:
    enabled: true
    size: 10Gi

  resources:
    requests:
      memory: 256Mi
      cpu: 250m
    limits:
      memory: 512Mi
      cpu: 500m
```

Co tu siÄ™ dzieje?
âœ” tworzony jest uÅ¼ytkownik appuser
âœ” tworzona jest baza appdb
âœ” hasÅ‚o dla roota (postgres)
âœ” PersistentVolume (dane nie zniknÄ… po restarcie)

## 5. Zainstaluj PostgreSQL
helm install postgresql bitnami/postgresql \
  -n database \
  -f postgresql/values.yaml

SprawdÅº status:
kubectl get pods -n database

Powinno byÄ‡:
postgresql-0   1/1   Running

## 6. SprawdÅº, czy baza i uÅ¼ytkownik istniejÄ…
### 6.1 Pobierz hasÅ‚o (jeÅ›li nie uÅ¼yÅ‚eÅ› wÅ‚asnego)

JeÅ›li nie podaÅ‚eÅ› haseÅ‚ w values.yaml, moÅ¼esz je pobraÄ‡:

kubectl get secret postgresql -n database \
  -o jsonpath="{.data.postgres-password}" | base64 -d

### 6.2 WejdÅº do kontenera PostgreSQL
kubectl exec -it postgresql-0 -n database -- psql \
  -U appuser \
  -d appdb

### 6.3 SprawdÅº bazÄ™ i uÅ¼ytkownika
\du
\l

PowinieneÅ› zobaczyÄ‡:
uÅ¼ytkownika appuser
bazÄ™ appdb

## 7. PoÅ‚Ä…czenie z PostgreSQL z aplikacji
### 7.1 Service w Kubernetes

Bitnami tworzy Service:

kubectl get svc -n database


Zwykle:

postgresql   ClusterIP   10.x.x.x   5432/TCP

### 7.2 Connection string (z wnÄ™trza klastra)
postgresql://appuser:strongpassword@postgresql.database.svc.cluster.local:5432/appdb

## 8. PoÅ‚Ä…czenie lokalne (port-forward)
kubectl port-forward svc/postgresql 5434:5432 -n database


PoÅ‚Ä…cz siÄ™ lokalnie:

psql -h 127.0.0.1 -p 5434 -U appuser -d appdb

## 9. Dodanie dodatkowej bazy / uÅ¼ytkownika (opcjonalnie)

JeÅ›li chcesz wiÄ™cej baz:

kubectl exec -it postgresql-0 -n database -- psql -U postgres

CREATE DATABASE otherdb;
CREATE USER otheruser WITH PASSWORD 'pass123';
GRANT ALL PRIVILEGES ON DATABASE otherdb TO otheruser;

## 10. UsuniÄ™cie PostgreSQL (uwaga na dane!)
helm uninstall postgresql -n database

âš ï¸ PV zostaje â€“ dane nadal sÄ… na dysku
Aby usunÄ…Ä‡ wszystko:

kubectl delete pvc -n database --all

## 11. Struktura â€produkcyjnaâ€ (rekomendacja)

hasÅ‚a â†’ Kubernetes Secrets

values.yaml â†’ bez haseÅ‚

backup â†’ pg_dump + CronJob

produkcja â†’ managed PostgreSQL (DO, AWS, GCP)


# Sealed Secret
W klastrze dziaÅ‚a controller Sealed Secrets
Ma on klucz prywatny, ktÃ³rego nie ma nikt poza klastrem
Ty lokalnie:
bierzesz Secret
szyfrujesz go narzÄ™dziem kubeseal
Do Gita trafia SealedSecret (zaszyfrowany YAML)
Controller w klastrze:
odszyfrowuje go
tworzy normalny Secret
ğŸ“Œ Nawet jeÅ›li ktoÅ› ukradnie repo â€” nie odczyta sekretÃ³w


# K9s
## Ubuntu
curl -sS https://webinstall.dev/k9s | bash
